{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "732cq65p5nmxjoitobm3",
   "authorId": "719307527079",
   "authorName": "USER",
   "authorEmail": "",
   "sessionId": "10841df1-3897-4bc9-9a4f-31e453a2514f",
   "lastEditTime": 1747948928587
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc417a9-d819-4b8f-b2fa-2f6eef1d7782",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": "## Module 3. Auto Clustering for Performance Tuning\n\nModule 3 is to focus on exploring and discovering auto clustering keys that can benefit the reporting workload.\n\n### 3.1 Analyze table size\n\nFirstly, let's analyze the table sizes. We can run the SHOW TABLES or query the INFORMATION_SHCEMA.TABLES view get those information."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "-- for operations & analysis\n",
    "use warehouse WH_SUMMIT25_PERF_OPS; \n",
    "\n",
    "show tables in schema sql_perf_optimization.public;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9c35e-a861-459a-b8bb-fbe1657ba9b3",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "select \n",
    "    table_name,\n",
    "    row_count, bytes\n",
    "from information_schema.tables\n",
    "where \n",
    "    table_catalog = 'SQL_PERF_OPTIMIZATION'\n",
    "    and table_schema = 'PUBLIC'\n",
    "    and table_name in (\n",
    "        'QUESTION', 'USER_PROFILE', \n",
    "        'CATEGORY', 'TRAFFIC'\n",
    "    )\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bf1d7-1cdf-44ac-8162-68461e86928e",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": "From the 4 main tables (`CATEGORY`, `QUESTION`, `TRAFFIC` and `USER_PROFILE`), only `USER_PROFILE` and `TRAFFIC` are big enough and worthy of auto clustering.\n\n### 3.2 Analyze Query Filters and Join Filters\n\nIn the real world, you may not be involved in table design. And as time goes, workload queries have been modified over time. You want to find out what are the most common local filters and join filters without going through each queries in the workload, which could be a lot of queries. This step is to mimic these common scenarios.\n\nSo let's analyze Query Filters and Join Filters used in those queries that we run in earlier step to discover table columns that may be good auto clustering key columns. Use the provided query snippet below to identify filter and join conditions frequently used in reporting queries on the TRAFFIC table. \n\nIn reality, the analysis query below may take you several iterations to narrow down the query filter (i.e., join_condition ilike '%t.%') as you understand your queries more and more. This exercise is done for you and we come up with the conditions that can provide a good representives of filters. and by combining with some of the reporting queries, we understand the alias names such as T or Traffic referring to the table TRAFFIC. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccaddb3-3507-4ce1-a59e-d37e45f49f45",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "-- analyze filters\n",
    "WITH filter_conditions AS (\n",
    "  SELECT\n",
    "    query_id,\n",
    "    query_tag,\n",
    "    CAST(\n",
    "      GET_PATH (operator_attributes, 'filter_condition') AS TEXT\n",
    "    ) AS filter_condition\n",
    "  FROM\n",
    "    base_query_stats\n",
    "  WHERE\n",
    "    operator_type ILIKE '%Filter%'\n",
    "    and ( filter_condition not ilike '%USER_PROFILE%'\n",
    "     and filter_condition not ilike '%QUESTION%')\n",
    "),\n",
    "join_conditions AS (\n",
    "    SELECT\n",
    "    query_id,\n",
    "    operator_attributes,\n",
    "    CAST(\n",
    "      GET_PATH (operator_attributes, 'equality_join_condition') AS TEXT\n",
    "    ) AS join_condition\n",
    "  FROM\n",
    "    base_query_stats\n",
    "    where join_condition is not null\n",
    "    and ( join_condition ilike '%t.%' or \n",
    "    join_condition ilike '%traffic.%' )\n",
    "), \n",
    "filters as (\n",
    "    SELECT\n",
    "      'Filter' AS condition_type,\n",
    "      query_id,\n",
    "      filter_condition AS condition\n",
    "    FROM\n",
    "      filter_conditions\n",
    "    WHERE\n",
    "      NOT filter_condition IS NULL\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      'Join' AS condition_type,\n",
    "      query_id,\n",
    "      join_condition AS condition\n",
    "    FROM\n",
    "      join_conditions\n",
    "    WHERE\n",
    "      NOT join_condition IS NULL\n",
    ")\n",
    "select distinct condition\n",
    "from filters\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30251b-05a0-414e-add9-aadafc964cd9",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "The filter result on Traffic Table looks like something as the following:\n",
    "- Use the provided query snippet to identify filter and join conditions frequently used in reporting queries on the TRAFFIC table. Local filter and join filter used are as follows:\n",
    "  - ```(T.TIMESTAMP >= '2025-01-01 00:00:00.000000000Z') AND (T.TIMESTAMP <= '2025-02-01 00:00:00.000000000Z')```\n",
    "  - ```(TO_TIMESTAMP_LTZ(T1.TIMESTAMP)) >= '2024-04-11 15:01:15.523000000Z'```\n",
    "  - ```(COUNT(DISTINCT T1.UUID)) > 10```\n",
    "  - ```(DATE_DIFFTIMESTAMPINDAYS(MIN(T.TIMESTAMP), MAX(T.TIMESTAMP))) > 0```\n",
    "  - ```(C.ID = T.CATEGORY_ID)```\n",
    "  - ```(T.UUID = USER_PROFILE.UUID)```\n",
    "\n",
    "Focus on columns from the traffic table such as TIMESTAMP, CATEGORY_ID, and UUID. Find out the distinct count of those 3 columns, since we typically use date instead of timestamp, so do a distinct count on TO_DATE(TIMESTAMP), instead of TIMESTAMP itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598669e8-b115-4b90-8642-5a25af4055b7",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "select\n",
    "    approx_count_distinct(to_date(timestamp)),\n",
    "    approx_count_distinct(category_id),\n",
    "    approx_count_distinct(uuid)\n",
    "from sql_perf_optimization.public.traffic;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970529d0-a494-492a-852f-15657649a524",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": [
    "To determine which columns are good candidates for clustering keys, we need to consider the following:\n",
    "\n",
    "- They should be actively used in selective filters\n",
    "- They should have a large enough number of distinct values to enable effective pruning\n",
    "- They should have a small enough number of distinct values to allow Snowflake to effectively group rows in the same micro-partitions.\n",
    "\n",
    "From the result above, we can see that the distinct count on the UUID column is way too large. The CATEGORY_ID column's distinct count is way too small, this will result many partitions share the same key, which will not help to improve the pruning. TO_DATE(TIMESTAMP) could be a better choice, however, give the fact that we have filters on both CATEGORY_ID and TIMESTAMP fields, having a combined clustering key on those two column would be a much better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ce2bb-6f70-4c2f-8ce8-d1c56ce03dce",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": "### 3.3 Add Auto Clustering Keys\n\n- Based on the analysis that TIMESTAMP and CATEGORY_ID are frequently filtered and suitable for clustering key columns, the auto-clustering key design on the TRAFFIC table is `(TO_DATE(TIMESTAMP) , CATEGORY_ID)`.\n- Remember that the order is important, and in our use case, TO_DATE(TIMESTAMP) in front will give us better performance because most of the queries will be date sensitive.\n\nLetâ€™s check on clustering information first on the `TRAFFIC` table first (you might want to copy the resultset into a text editor to see the full result)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc3265-b476-4818-b2ab-a10e55a81df9",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "SELECT SYSTEM$CLUSTERING_INFORMATION(\n",
    "    'SQL_PERF_OPTIMIZATION.PUBLIC.TRAFFIC' , \n",
    "    '(TO_DATE(TIMESTAMP),CATEGORY_ID)'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9e4e9-2adc-4eae-91fe-619d6ab09d84",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "The result would like something like below:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"cluster_by_keys\" : \"LINEAR(TO_DATE(TIMESTAMP),CATEGORY_ID)\",\n",
    "  \"total_partition_count\" : 1014,\n",
    "  \"total_constant_partition_count\" : 0,\n",
    "  \"average_overlaps\" : 1013.0,\n",
    "  \"average_depth\" : 1014.0,\n",
    "  \"partition_depth_histogram\" : {\n",
    "    \"00000\" : 0,\n",
    "    \"00001\" : 0,\n",
    "    \"00002\" : 0,\n",
    "    \"00003\" : 0,\n",
    "    \"00004\" : 0,\n",
    "    \"00005\" : 0,\n",
    "    \"00006\" : 0,\n",
    "    \"00007\" : 0,\n",
    "    \"00008\" : 0,\n",
    "    \"00009\" : 0,\n",
    "    \"00010\" : 0,\n",
    "    \"00011\" : 0,\n",
    "    \"00012\" : 0,\n",
    "    \"00013\" : 0,\n",
    "    \"00014\" : 0,\n",
    "    \"00015\" : 0,\n",
    "    \"00016\" : 0,\n",
    "    \"01024\" : 1014\n",
    "  },\n",
    "  \"clustering_errors\" : [ ]\n",
    "}\n",
    "```\n",
    "\n",
    "A couple of things here to note:\n",
    "\n",
    "- The cardinality (the distinct number of values) on those two columns is very high, meaning that there are many different distinct values. This is due to the value of TIMESTAMP, which records up to milliseconds. This is OK when distributing the data across different partitions, however, it will be very expensive to maintain, as one single new value from the middle of the partition will result in all data from later TIMESTAMP values being shifted across all the remaining partitions.\n",
    "- There are 539 partitions in the table; however, the values of AVERAGE_OVERLAPS and AVERAGE_DEPTH are very close to this value. This means that pretty much all partitions have overlapping values, so this table is not well clustered at all.\n",
    "- For more information on how to interpret the clustering information, please refer to Clustering Information Maintained for Micro-partitions (https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions) and SYSTEM$CLUSTERING_INFORMATION (https://docs.snowflake.com/en/sql-reference/functions/system_clustering_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aafa0d1-348b-4653-abbc-16882324c5ec",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "We can use the `SYSTEM` function `ESTIMATE_AUTOMATIC_CLUSTERING_COSTS` to estimate the cost of autoclustering a table. It might take sometime to run (> 10 minutes), To save sometime, we will skip this step, but you are welcome to run it after the lab.\n",
    "\n",
    "Command as below:\n",
    "\n",
    "```sql\n",
    "SELECT SYSTEM$ESTIMATE_AUTOMATIC_CLUSTERING_COSTS(\n",
    "    'TRAFFIC', \n",
    "    '(TO_DATE(TIMESTAMP),CATEGORY_ID)'\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b66139-bc4d-49bd-a1fe-565cfed3c56a",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "Now we are ready to add clustering keys to the `TRAFFIC` table.\n",
    "\n",
    "DO NOT RUN the following command in the lab as we have already done so to the `TRAFFIC_CLUSTERED` table, which will be used in the following labs. There is latency for the auto clustering service to kick in and finish on time within the lab allotted time. \n",
    "\n",
    "```sql\n",
    "ALTER TABLE TRAFFIC CLUSTER BY (TO_DATE(TIMESTAMP), CATEGORY_ID);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa49175-b90e-46b3-a073-5cb7ba522c3d",
   "metadata": {
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "Confirm clustering information for the table `TRAFFIC_CLUSTERED`.\n",
    "\n",
    "Since the clustering columns have been defined, we do not need to enter the columns information into function `SYSTEM$ESTIMATE_AUTOMATIC_CLUSTERING_COSTS` anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2390c-6614-4387-bd71-3538cf43c575",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "SELECT SYSTEM$CLUSTERING_INFORMATION(\n",
    "    'TRAFFIC_CLUSTERED'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6893df3-cf11-4688-ae3d-1a47994026ff",
   "metadata": {
    "collapsed": false,
    "name": "cell16"
   },
   "source": [
    "Since the table was newly built, the clustering information for the `TRAFFIC_CLUSTERED` table should be optimized from the beginning, similar to the below:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"cluster_by_keys\" : \"LINEAR(TO_DATE(TIMESTAMP), CATEGORY_ID)\",\n",
    "  \"total_partition_count\" : 871,\n",
    "  \"total_constant_partition_count\" : 0,\n",
    "  \"average_overlaps\" : 1.8422,\n",
    "  \"average_depth\" : 2.248,\n",
    "  \"partition_depth_histogram\" : {\n",
    "    \"00000\" : 0,\n",
    "    \"00001\" : 0,\n",
    "    \"00002\" : 201,\n",
    "    \"00003\" : 359,\n",
    "    \"00004\" : 217,\n",
    "    \"00005\" : 82,\n",
    "    \"00006\" : 12,\n",
    "    \"00007\" : 0,\n",
    "    \"00008\" : 0,\n",
    "    \"00009\" : 0,\n",
    "    \"00010\" : 0,\n",
    "    \"00011\" : 0,\n",
    "    \"00012\" : 0,\n",
    "    \"00013\" : 0,\n",
    "    \"00014\" : 0,\n",
    "    \"00015\" : 0,\n",
    "    \"00016\" : 0\n",
    "  },\n",
    "  \"clustering_errors\" : [ ]\n",
    "}\n",
    "```\n",
    "\n",
    "We can see that the average_overlaps dropped from 1013 to 1.8 and average_depth dropped from to 1014 to 2.2.\n",
    "\n",
    "Different acounts might get different results, but should not be too much different.\n",
    "\n",
    "We are now ready to test the workload again and compare the result."
   ]
  }
 ]
}